{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "128ef6b8",
   "metadata": {},
   "source": [
    "# üõ©Ô∏è Aircraft Engine RUL Prediction - ML/DL Models\n",
    "\n",
    "## Remaining Useful Life Prediction using Machine Learning & Deep Learning\n",
    "\n",
    "This notebook builds and compares multiple approaches for predicting Remaining Useful Life (RUL) of aircraft turbofan engines using the NASA C-MAPSS dataset.\n",
    "\n",
    "### Models Implemented:\n",
    "1. **Random Forest Regressor** - Baseline ML model\n",
    "2. **Gradient Boosting (XGBoost)** - Advanced ensemble method\n",
    "3. **LSTM Neural Network** - Deep learning for sequence modeling\n",
    "4. **1D CNN** - Convolutional approach for time series\n",
    "\n",
    "### Evaluation Metric:\n",
    "The PHM scoring function penalizes late predictions more heavily than early ones:\n",
    "$$s = \\sum_{i=1}^{n} \\begin{cases} e^{-d/a_1} - 1 & \\text{if } d < 0 \\text{ (early)} \\\\ e^{d/a_2} - 1 & \\text{if } d \\geq 0 \\text{ (late)} \\end{cases}$$\n",
    "where $d = \\hat{RUL} - RUL_{true}$, $a_1 = 13$, $a_2 = 10$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b78bd",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a951623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è XGBoost not installed. Run: pip install xgboost\")\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "# Deep Learning\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential, Model\n",
    "    from tensorflow.keras.layers import (Dense, LSTM, Dropout, Conv1D, MaxPooling1D, \n",
    "                                          Flatten, BatchNormalization, Input, Bidirectional)\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "    print(f\"‚úÖ TensorFlow version: {tf.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è TensorFlow not installed. Run: pip install tensorflow\")\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "COLORS = {\n",
    "    'primary': '#1E3A5F',\n",
    "    'secondary': '#3D7EAA',\n",
    "    'accent': '#F39C12',\n",
    "    'success': '#27AE60',\n",
    "    'danger': '#E74C3C',\n",
    "    'warning': '#F1C40F'\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc22fd",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75810892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path\n",
    "DATA_PATH = Path(r\"C:\\Users\\Prshant Verma\\Documents\\Projects\\DataSets\\aircraft-engine-failure-data\")\n",
    "\n",
    "# Column definitions\n",
    "index_columns = ['unit_number', 'time_cycles']\n",
    "operational_settings = ['op_setting_1', 'op_setting_2', 'op_setting_3']\n",
    "\n",
    "sensor_columns = [\n",
    "    'T2', 'T24', 'T30', 'T48', 'T50', 'P2', 'P15', 'P30',\n",
    "    'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', 'farB',\n",
    "    'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32'\n",
    "]\n",
    "\n",
    "column_names = index_columns + operational_settings + sensor_columns\n",
    "\n",
    "# Sensors to drop (low variance based on EDA)\n",
    "drop_sensors = ['T2', 'P2', 'P15', 'Nf_dmd', 'PCNfR_dmd', 'farB']\n",
    "\n",
    "# Maximum RUL cap (piecewise linear degradation assumption)\n",
    "RUL_CAP = 125\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfaeaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_id='FD001'):\n",
    "    \"\"\"Load train, test, and RUL data for a given dataset.\"\"\"\n",
    "    \n",
    "    train_df = pd.read_csv(\n",
    "        DATA_PATH / f'train_{dataset_id}.txt',\n",
    "        sep='\\\\s+', header=None, names=column_names\n",
    "    )\n",
    "    \n",
    "    test_df = pd.read_csv(\n",
    "        DATA_PATH / f'test_{dataset_id}.txt',\n",
    "        sep='\\\\s+', header=None, names=column_names\n",
    "    )\n",
    "    \n",
    "    rul_df = pd.read_csv(\n",
    "        DATA_PATH / f'RUL_{dataset_id}.txt',\n",
    "        sep='\\\\s+', header=None, names=['RUL']\n",
    "    )\n",
    "    \n",
    "    return train_df, test_df, rul_df\n",
    "\n",
    "\n",
    "def compute_rul(df, rul_cap=RUL_CAP):\n",
    "    \"\"\"Compute RUL for training data with optional capping.\"\"\"\n",
    "    max_cycles = df.groupby('unit_number')['time_cycles'].max()\n",
    "    \n",
    "    df = df.copy()\n",
    "    df['RUL'] = df.apply(\n",
    "        lambda row: max_cycles[row['unit_number']] - row['time_cycles'], \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Cap RUL (piecewise linear assumption)\n",
    "    if rul_cap:\n",
    "        df['RUL'] = df['RUL'].clip(upper=rul_cap)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_features(df):\n",
    "    \"\"\"Add rolling statistics and derived features.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Useful sensors (excluding low variance)\n",
    "    useful_sensors = [s for s in sensor_columns if s not in drop_sensors]\n",
    "    \n",
    "    # Rolling statistics per engine\n",
    "    for sensor in useful_sensors:\n",
    "        # Rolling mean (window = 5 cycles)\n",
    "        df[f'{sensor}_roll_mean'] = df.groupby('unit_number')[sensor].transform(\n",
    "            lambda x: x.rolling(window=5, min_periods=1).mean()\n",
    "        )\n",
    "        \n",
    "        # Rolling std (window = 5 cycles)\n",
    "        df[f'{sensor}_roll_std'] = df.groupby('unit_number')[sensor].transform(\n",
    "            lambda x: x.rolling(window=5, min_periods=1).std()\n",
    "        )\n",
    "    \n",
    "    # Fill NaN from rolling operations\n",
    "    df = df.fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Load FD001 dataset\n",
    "train_df, test_df, rul_df = load_dataset('FD001')\n",
    "\n",
    "# Compute RUL for training data\n",
    "train_df = compute_rul(train_df)\n",
    "\n",
    "# Add engineered features\n",
    "train_df = add_features(train_df)\n",
    "test_df = add_features(test_df)\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Number of features: {len([c for c in train_df.columns if c not in index_columns + ['RUL']])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97093d10",
   "metadata": {},
   "source": [
    "## 3. Feature Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd16b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns (exclude index and target)\n",
    "feature_columns = [c for c in train_df.columns if c not in index_columns + ['RUL']]\n",
    "\n",
    "# Remove low variance sensors from features\n",
    "feature_columns = [c for c in feature_columns if not any(s in c for s in drop_sensors)]\n",
    "\n",
    "print(f\"Number of features: {len(feature_columns)}\")\n",
    "print(f\"Features: {feature_columns[:10]}...\")  # Show first 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c22839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data for ML models\n",
    "X_train_full = train_df[feature_columns].values\n",
    "y_train_full = train_df['RUL'].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_full)\n",
    "\n",
    "# Split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_scaled, y_train_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c82f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "# For test set, we use the LAST observation of each engine\n",
    "test_last = test_df.groupby('unit_number').last().reset_index()\n",
    "\n",
    "X_test = test_last[feature_columns].values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test = rul_df['RUL'].values\n",
    "\n",
    "print(f\"Test set: {X_test_scaled.shape}\")\n",
    "print(f\"True RUL values: {len(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab868b",
   "metadata": {},
   "source": [
    "## 4. Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b2a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phm_score(y_true, y_pred, a1=13, a2=10):\n",
    "    \"\"\"\n",
    "    PHM Challenge scoring function.\n",
    "    Penalizes late predictions more heavily than early predictions.\n",
    "    \n",
    "    Args:\n",
    "        y_true: True RUL values\n",
    "        y_pred: Predicted RUL values\n",
    "        a1: Parameter for early predictions (default: 13)\n",
    "        a2: Parameter for late predictions (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "        Total PHM score (lower is better)\n",
    "    \"\"\"\n",
    "    d = y_pred - y_true  # Estimated - True\n",
    "    \n",
    "    scores = np.where(\n",
    "        d < 0,\n",
    "        np.exp(-d / a1) - 1,  # Early prediction\n",
    "        np.exp(d / a2) - 1    # Late prediction\n",
    "    )\n",
    "    \n",
    "    return np.sum(scores)\n",
    "\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"Comprehensive model evaluation.\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    score = phm_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üìä {model_name} Performance\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"  RMSE:      {rmse:.2f} cycles\")\n",
    "    print(f\"  MAE:       {mae:.2f} cycles\")\n",
    "    print(f\"  R¬≤ Score:  {r2:.4f}\")\n",
    "    print(f\"  PHM Score: {score:.2f} (lower is better)\")\n",
    "    \n",
    "    return {'model': model_name, 'rmse': rmse, 'mae': mae, 'r2': r2, 'phm_score': score}\n",
    "\n",
    "\n",
    "def plot_predictions(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"Plot predicted vs actual RUL.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[0].scatter(y_true, y_pred, alpha=0.6, c=COLORS['primary'], s=50)\n",
    "    axes[0].plot([0, max(y_true)], [0, max(y_true)], 'r--', linewidth=2, label='Perfect prediction')\n",
    "    axes[0].set_xlabel('True RUL (cycles)', fontsize=12)\n",
    "    axes[0].set_ylabel('Predicted RUL (cycles)', fontsize=12)\n",
    "    axes[0].set_title(f'{model_name}: Predicted vs True RUL', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Error distribution\n",
    "    errors = y_pred - y_true\n",
    "    axes[1].hist(errors, bins=30, color=COLORS['secondary'], edgecolor='white', alpha=0.8)\n",
    "    axes[1].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero error')\n",
    "    axes[1].axvline(errors.mean(), color='green', linestyle='-', linewidth=2, \n",
    "                    label=f'Mean error: {errors.mean():.1f}')\n",
    "    axes[1].set_xlabel('Prediction Error (cycles)', fontsize=12)\n",
    "    axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1].set_title(f'{model_name}: Error Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Store results for comparison\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d826a0",
   "metadata": {},
   "source": [
    "## 5. Model 1: Random Forest Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3256b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üå≤ Training Random Forest Regressor...\")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_val_pred = rf_model.predict(X_val)\n",
    "rf_test_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate on validation set\n",
    "print(\"\\n--- Validation Set ---\")\n",
    "rf_val_result = evaluate_model(y_val, rf_val_pred, \"Random Forest (Val)\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\n--- Test Set ---\")\n",
    "rf_test_result = evaluate_model(y_test, rf_test_pred, \"Random Forest (Test)\")\n",
    "results.append(rf_test_result)\n",
    "\n",
    "# Plot predictions\n",
    "plot_predictions(y_test, rf_test_pred, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d727c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_features = feature_importance.head(20)\n",
    "ax.barh(top_features['feature'], top_features['importance'], color=COLORS['accent'])\n",
    "ax.set_xlabel('Feature Importance', fontsize=12)\n",
    "ax.set_title('Random Forest - Top 20 Important Features', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e29b6",
   "metadata": {},
   "source": [
    "## 6. Model 2: XGBoost Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c43e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if XGBOOST_AVAILABLE:\n",
    "    print(\"üöÄ Training XGBoost Regressor...\")\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    xgb_val_pred = xgb_model.predict(X_val)\n",
    "    xgb_test_pred = xgb_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\n--- Validation Set ---\")\n",
    "    xgb_val_result = evaluate_model(y_val, xgb_val_pred, \"XGBoost (Val)\")\n",
    "    \n",
    "    print(\"\\n--- Test Set ---\")\n",
    "    xgb_test_result = evaluate_model(y_test, xgb_test_pred, \"XGBoost (Test)\")\n",
    "    results.append(xgb_test_result)\n",
    "    \n",
    "    # Plot predictions\n",
    "    plot_predictions(y_test, xgb_test_pred, \"XGBoost\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è XGBoost not available. Skipping...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e3530",
   "metadata": {},
   "source": [
    "## 7. Prepare Sequence Data for Deep Learning\n",
    "\n",
    "LSTM and CNN models require sequence data. We'll create sliding windows of sensor readings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ee6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 30  # Use last 30 cycles for prediction\n",
    "\n",
    "def create_sequences(df, feature_cols, sequence_length=SEQUENCE_LENGTH):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM/CNN models.\n",
    "    Each sequence is the last 'sequence_length' observations for an engine.\n",
    "    Target is the RUL at the last timestep.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for engine_id in df['unit_number'].unique():\n",
    "        engine_data = df[df['unit_number'] == engine_id].sort_values('time_cycles')\n",
    "        \n",
    "        # Get features and RUL\n",
    "        features = engine_data[feature_cols].values\n",
    "        rul = engine_data['RUL'].values\n",
    "        \n",
    "        # Create sequences using sliding window\n",
    "        for i in range(len(features) - sequence_length + 1):\n",
    "            sequences.append(features[i:i + sequence_length])\n",
    "            targets.append(rul[i + sequence_length - 1])\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "\n",
    "def create_test_sequences(df, feature_cols, sequence_length=SEQUENCE_LENGTH):\n",
    "    \"\"\"\n",
    "    Create test sequences - one per engine (using last observations).\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    \n",
    "    for engine_id in sorted(df['unit_number'].unique()):\n",
    "        engine_data = df[df['unit_number'] == engine_id].sort_values('time_cycles')\n",
    "        features = engine_data[feature_cols].values\n",
    "        \n",
    "        # Pad if not enough data\n",
    "        if len(features) < sequence_length:\n",
    "            padding = np.zeros((sequence_length - len(features), features.shape[1]))\n",
    "            features = np.vstack([padding, features])\n",
    "        else:\n",
    "            features = features[-sequence_length:]\n",
    "        \n",
    "        sequences.append(features)\n",
    "    \n",
    "    return np.array(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the full training data first\n",
    "train_df_scaled = train_df.copy()\n",
    "train_df_scaled[feature_columns] = scaler.fit_transform(train_df[feature_columns])\n",
    "\n",
    "test_df_scaled = test_df.copy()\n",
    "test_df_scaled[feature_columns] = scaler.transform(test_df[feature_columns])\n",
    "\n",
    "# Create sequences\n",
    "X_seq, y_seq = create_sequences(train_df_scaled, feature_columns)\n",
    "X_test_seq = create_test_sequences(test_df_scaled, feature_columns)\n",
    "\n",
    "print(f\"Training sequences shape: {X_seq.shape}\")\n",
    "print(f\"Training targets shape: {y_seq.shape}\")\n",
    "print(f\"Test sequences shape: {X_test_seq.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb448bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sequences into train/validation\n",
    "X_seq_train, X_seq_val, y_seq_train, y_seq_val = train_test_split(\n",
    "    X_seq, y_seq, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training sequences: {X_seq_train.shape}\")\n",
    "print(f\"Validation sequences: {X_seq_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c199db",
   "metadata": {},
   "source": [
    "## 8. Model 3: LSTM Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b21d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    print(\"üß† Building LSTM Model...\")\n",
    "    \n",
    "    n_features = X_seq_train.shape[2]\n",
    "    \n",
    "    def build_lstm_model(seq_length, n_features):\n",
    "        model = Sequential([\n",
    "            # First LSTM layer\n",
    "            LSTM(64, return_sequences=True, input_shape=(seq_length, n_features)),\n",
    "            Dropout(0.2),\n",
    "            BatchNormalization(),\n",
    "            \n",
    "            # Second LSTM layer\n",
    "            LSTM(32, return_sequences=False),\n",
    "            Dropout(0.2),\n",
    "            BatchNormalization(),\n",
    "            \n",
    "            # Dense layers\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(16, activation='relu'),\n",
    "            \n",
    "            # Output layer\n",
    "            Dense(1)\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    lstm_model = build_lstm_model(SEQUENCE_LENGTH, n_features)\n",
    "    lstm_model.summary()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è TensorFlow not available. Skipping LSTM...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    print(\"üèãÔ∏è Training LSTM Model...\")\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    ]\n",
    "    \n",
    "    # Train\n",
    "    history_lstm = lstm_model.fit(\n",
    "        X_seq_train, y_seq_train,\n",
    "        validation_data=(X_seq_val, y_seq_val),\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].plot(history_lstm.history['loss'], label='Train Loss')\n",
    "    axes[0].plot(history_lstm.history['val_loss'], label='Val Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss (MSE)')\n",
    "    axes[0].set_title('LSTM Training Loss', fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].plot(history_lstm.history['mae'], label='Train MAE')\n",
    "    axes[1].plot(history_lstm.history['val_mae'], label='Val MAE')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].set_title('LSTM Training MAE', fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf991ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    # Predictions\n",
    "    lstm_val_pred = lstm_model.predict(X_seq_val).flatten()\n",
    "    lstm_test_pred = lstm_model.predict(X_test_seq).flatten()\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\n--- Validation Set ---\")\n",
    "    lstm_val_result = evaluate_model(y_seq_val, lstm_val_pred, \"LSTM (Val)\")\n",
    "    \n",
    "    print(\"\\n--- Test Set ---\")\n",
    "    lstm_test_result = evaluate_model(y_test, lstm_test_pred, \"LSTM (Test)\")\n",
    "    results.append(lstm_test_result)\n",
    "    \n",
    "    # Plot predictions\n",
    "    plot_predictions(y_test, lstm_test_pred, \"LSTM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266600fc",
   "metadata": {},
   "source": [
    "## 9. Model 4: 1D CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb01313",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    print(\"üî¨ Building 1D CNN Model...\")\n",
    "    \n",
    "    def build_cnn_model(seq_length, n_features):\n",
    "        model = Sequential([\n",
    "            # First Conv block\n",
    "            Conv1D(64, kernel_size=5, activation='relu', padding='same',\n",
    "                   input_shape=(seq_length, n_features)),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Dropout(0.2),\n",
    "            \n",
    "            # Second Conv block\n",
    "            Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Dropout(0.2),\n",
    "            \n",
    "            # Third Conv block\n",
    "            Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "            \n",
    "            # Flatten and Dense\n",
    "            Flatten(),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(32, activation='relu'),\n",
    "            \n",
    "            # Output\n",
    "            Dense(1)\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    cnn_model = build_cnn_model(SEQUENCE_LENGTH, n_features)\n",
    "    cnn_model.summary()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è TensorFlow not available. Skipping CNN...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4edb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    print(\"üèãÔ∏è Training CNN Model...\")\n",
    "    \n",
    "    # Train\n",
    "    history_cnn = cnn_model.fit(\n",
    "        X_seq_train, y_seq_train,\n",
    "        validation_data=(X_seq_val, y_seq_val),\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].plot(history_cnn.history['loss'], label='Train Loss')\n",
    "    axes[0].plot(history_cnn.history['val_loss'], label='Val Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss (MSE)')\n",
    "    axes[0].set_title('CNN Training Loss', fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].plot(history_cnn.history['mae'], label='Train MAE')\n",
    "    axes[1].plot(history_cnn.history['val_mae'], label='Val MAE')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].set_title('CNN Training MAE', fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baccc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    # Predictions\n",
    "    cnn_val_pred = cnn_model.predict(X_seq_val).flatten()\n",
    "    cnn_test_pred = cnn_model.predict(X_test_seq).flatten()\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\n--- Validation Set ---\")\n",
    "    cnn_val_result = evaluate_model(y_seq_val, cnn_val_pred, \"CNN (Val)\")\n",
    "    \n",
    "    print(\"\\n--- Test Set ---\")\n",
    "    cnn_test_result = evaluate_model(y_test, cnn_test_pred, \"CNN (Test)\")\n",
    "    results.append(cnn_test_result)\n",
    "    \n",
    "    # Plot predictions\n",
    "    plot_predictions(y_test, cnn_test_pred, \"1D CNN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd28f5c",
   "metadata": {},
   "source": [
    "## 10. Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d1119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä MODEL COMPARISON - TEST SET PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
    "\n",
    "metrics = ['rmse', 'mae', 'r2', 'phm_score']\n",
    "titles = ['RMSE (Lower Better)', 'MAE (Lower Better)', 'R¬≤ Score (Higher Better)', 'PHM Score (Lower Better)']\n",
    "colors_list = [COLORS['primary'], COLORS['secondary'], COLORS['success'], COLORS['accent']]\n",
    "\n",
    "for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    ax = axes[i]\n",
    "    bars = ax.bar(results_df['model'], results_df[metric], color=colors_list[i], alpha=0.8)\n",
    "    ax.set_ylabel(metric.upper())\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, results_df[metric]):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                f'{val:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.suptitle('Model Performance Comparison (FD001 Dataset)', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbace130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model identification\n",
    "best_rmse = results_df.loc[results_df['rmse'].idxmin()]\n",
    "best_phm = results_df.loc[results_df['phm_score'].idxmin()]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ BEST MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìå Best by RMSE: {best_rmse['model']}\")\n",
    "print(f\"   RMSE = {best_rmse['rmse']:.2f}, PHM Score = {best_rmse['phm_score']:.2f}\")\n",
    "\n",
    "print(f\"\\nüìå Best by PHM Score: {best_phm['model']}\")\n",
    "print(f\"   PHM Score = {best_phm['phm_score']:.2f}, RMSE = {best_phm['rmse']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a604957b",
   "metadata": {},
   "source": [
    "## 11. Visualize All Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea0ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all predictions\n",
    "all_predictions = {\n",
    "    'True RUL': y_test,\n",
    "    'Random Forest': rf_test_pred,\n",
    "}\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    all_predictions['XGBoost'] = xgb_test_pred\n",
    "    \n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    all_predictions['LSTM'] = lstm_test_pred\n",
    "    all_predictions['CNN'] = cnn_test_pred\n",
    "\n",
    "# Plot all predictions together\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "x = np.arange(len(y_test))\n",
    "width = 0.15\n",
    "\n",
    "for i, (name, preds) in enumerate(all_predictions.items()):\n",
    "    offset = (i - len(all_predictions)/2) * width\n",
    "    if name == 'True RUL':\n",
    "        ax.bar(x + offset, preds, width, label=name, color=COLORS['danger'], alpha=0.9)\n",
    "    else:\n",
    "        ax.bar(x + offset, preds, width, label=name, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Engine ID', fontsize=12)\n",
    "ax.set_ylabel('RUL (Cycles)', fontsize=12)\n",
    "ax.set_title('RUL Predictions Comparison Across All Models', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xticks(x[::10])\n",
    "ax.set_xticklabels([f'E{i+1}' for i in x[::10]])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6a4bb",
   "metadata": {},
   "source": [
    "## 12. Summary and Conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3aa75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üìã SUMMARY: REMAINING USEFUL LIFE PREDICTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüéØ PROBLEM\")\n",
    "print(\"   Predict the number of operational cycles remaining before\")\n",
    "print(\"   aircraft turbofan engine failure using sensor data.\")\n",
    "\n",
    "print(\"\\nüìä DATASET: NASA C-MAPSS FD001\")\n",
    "print(\"   ‚Ä¢ 100 training engines (run to failure)\")\n",
    "print(\"   ‚Ä¢ 100 test engines\")\n",
    "print(\"   ‚Ä¢ 21 sensor measurements + 3 operational settings\")\n",
    "print(\"   ‚Ä¢ Single operating condition, single fault mode (HPC degradation)\")\n",
    "\n",
    "print(\"\\nüîß APPROACH\")\n",
    "print(\"   1. Feature Engineering:\")\n",
    "print(\"      - Rolling statistics (mean, std)\")\n",
    "print(\"      - Dropped low-variance sensors\")\n",
    "print(\"      - RUL capping at 125 cycles (piecewise linear)\")\n",
    "print(\"   \")\n",
    "print(\"   2. Models Implemented:\")\n",
    "print(\"      - Random Forest Regressor\")\n",
    "print(\"      - XGBoost Regressor\") \n",
    "print(\"      - LSTM Neural Network (sequence-based)\")\n",
    "print(\"      - 1D CNN (sequence-based)\")\n",
    "\n",
    "print(\"\\nüìà KEY INSIGHTS\")\n",
    "print(\"   ‚Ä¢ Deep learning models (LSTM, CNN) capture temporal patterns\")\n",
    "print(\"   ‚Ä¢ Ensemble methods work well without sequence modeling\")\n",
    "print(\"   ‚Ä¢ PHM scoring penalizes late predictions more heavily\")\n",
    "print(\"   ‚Ä¢ Feature engineering significantly improves performance\")\n",
    "\n",
    "print(\"\\nüöÄ POTENTIAL IMPROVEMENTS\")\n",
    "print(\"   ‚Ä¢ Bidirectional LSTM / Attention mechanisms\")\n",
    "print(\"   ‚Ä¢ Ensemble of multiple models\")\n",
    "print(\"   ‚Ä¢ Hyperparameter tuning with cross-validation\")\n",
    "print(\"   ‚Ä¢ Physics-informed neural networks\")\n",
    "print(\"   ‚Ä¢ Test on more complex datasets (FD002, FD003, FD004)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616bdef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö References\n",
    "\n",
    "1. Saxena, A., Goebel, K., Simon, D., & Eklund, N. (2008). **Damage Propagation Modeling for Aircraft Engine Run-to-Failure Simulation**. International Conference on Prognostics and Health Management (PHM08).\n",
    "\n",
    "2. NASA Prognostics Center of Excellence Data Repository: [https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/)\n",
    "\n",
    "---\n",
    "\n",
    "**End of Notebook**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
